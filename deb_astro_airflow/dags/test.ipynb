{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pd.read_csv('../datasets/movie_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hehe\n"
     ]
    }
   ],
   "source": [
    "dataset_file_1 = os.path.abspath(\"../datasets/movie_review.csv\")\n",
    "\n",
    "if os.path.exists(dataset_file_1):\n",
    "    print('Hehe')\n",
    "else:\n",
    "    pass\n",
    "    # logging.error(f\"File not found: {dataset_file_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/path/to/your/dataset_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'user_purchase' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "def create_postgres_table(\n",
    "    database_name, \n",
    "    user, \n",
    "    password, \n",
    "    host, \n",
    "    port, \n",
    "    table_name, \n",
    "    columns_definition\n",
    "):\n",
    " \n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=database_name,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=host,\n",
    "            port=port\n",
    "        )\n",
    "        \n",
    "        # Create a cursor object\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # SQL command to create the table\n",
    "        create_table_sql = f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                {columns_definition}\n",
    "            )\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the SQL command\n",
    "        cur.execute(create_table_sql)\n",
    "        \n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Table '{table_name}' created successfully.\")\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(f\"Error: {error}\")\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if conn is not None:\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "\n",
    "# Example usage:\n",
    "create_postgres_table(\n",
    "    database_name=\"deb_wizeline_db_pius\",\n",
    "    user=\"deb_pius\",\n",
    "    password=\"deb_pius@8\",\n",
    "    host=\"34.29.245.56\",\n",
    "    port=5432,  # Default PostgreSQL port\n",
    "    table_name=\"user_purchase\",\n",
    "    columns_definition=\"\"\"\n",
    "                    invoiceNo varchar(20),\n",
    "                    stockCode varchar(20),\n",
    "                    description varchar(1000),\n",
    "                    quantity numeric,\n",
    "                    invoiceDate timestamp,\n",
    "                    unitPrice numeric(8,3),\n",
    "                    customerID varchar(20),\n",
    "                    country varchar(20)\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: module 'psycopg2' has no attribute 'extras'\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def insert_data_into_postgres(\n",
    "    database_name, user, password, host, port, table_name, df\n",
    "):\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=database_name,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=host,\n",
    "            port=port\n",
    "        )\n",
    "\n",
    "        # Create a cursor object\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Convert DataFrame to a list of tuples\n",
    "        data_to_insert = [tuple(row) for row in df.to_records(index=False)]\n",
    "\n",
    "        # SQL command for insertion\n",
    "        insert_query = f\"\"\"\n",
    "            INSERT INTO {table_name} \n",
    "            VALUES %s\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the insertion\n",
    "        psycopg2.extras.execute_values(\n",
    "            cur, insert_query, data_to_insert, template=None, page_size=100\n",
    "        )\n",
    "\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Data inserted into '{table_name}' successfully.\")\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(f\"Error: {error}\")\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if conn is not None:\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "insert_data_into_postgres(\n",
    "    database_name=\"deb_wizeline_db_pius\",\n",
    "    user=\"deb_pius\",\n",
    "    password=\"deb_pius@8\",\n",
    "    host=\"34.29.245.56\",\n",
    "    port=5432,  # Default PostgreSQL port\n",
    "    table_name=\"user_purchase\",\n",
    "    df=path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: invalid literal for int() with base 10: '@34.29.245.56:5432'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def insert_data_into_postgres(database_url, table_name, df):\n",
    "    try:\n",
    "        # Create a SQLAlchemy engine\n",
    "        engine = create_engine(database_url)\n",
    "\n",
    "        # Insert data into the PostgreSQL table\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "        print(f\"Data inserted into '{table_name}' successfully.\")\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"Error: {error}\")\n",
    "\n",
    "# Example usage:\n",
    "df = path\n",
    "database_url = \"postgresql://deb_pius:deb_pius@8:@34.29.245.56:5432/deb_wizeline_db_pius\"\n",
    "table_name = \"user_purchase\"\n",
    "insert_data_into_postgres(database_url, table_name, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path['StockCode'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../datasets/movie_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>review_str</th>\n",
       "      <th>id_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13756</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15738</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15727</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cid                                         review_str  id_review\n",
       "0  13756  Once again Mr. Costner has dragged out a movie...          1\n",
       "1  15738  This is an example of why the majority of acti...          2\n",
       "2  15727  First of all I hate those moronic rappers, who...          3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Tokenization\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"review_str\", outputCol=\"review_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21944\\3609320896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Tokenize the 'review_str' column and add the result to a new column 'review_token'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtokenized_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Pius.Kitheru\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Pius.Kitheru\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Pius.Kitheru\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5573\u001b[0m         ):\n\u001b[0;32m   5574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize the 'review_str' column and add the result to a new column 'review_token'\n",
    "tokenized_df = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show the result\n",
    "tokenized_df.select(\"cid\", \"review_token\").show(truncate=False)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
